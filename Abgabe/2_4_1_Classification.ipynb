{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open csv file\n",
    "import pandas as pd\n",
    "train = pd.read_csv('../Data/IMDBsentiment/IMDBsentiment/Train.csv')\n",
    "test = pd.read_csv('../Data/IMDBsentiment/IMDBsentiment/Test.csv')\n",
    "valid = pd.read_csv('../Data/IMDBsentiment/IMDBsentiment/Valid.csv')\n",
    "\n",
    "# show first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all characters except a-z, A-Z, 0-9, äöüÄÖÜß, ., !, ?\n",
    "# remove double spaces\n",
    "# convert to lower case\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9äöüÄÖÜß.,!?]', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i grew up b. 1965 watching and loving the thun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i put this movie in my dvd player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though i have great interest in biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im a die hard dads army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i grew up b. 1965 watching and loving the thun...      0\n",
       "1  when i put this movie in my dvd player, and sa...      0\n",
       "2  why do people who do not know what a particula...      0\n",
       "3  even though i have great interest in biblical ...      0\n",
       "4  im a die hard dads army fan and nothing will e...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = train['text'].apply(clean_text)\n",
    "test['text'] = test['text'].apply(clean_text)\n",
    "valid['text'] = valid['text'].apply(clean_text)\n",
    "\n",
    "# show first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and labels\n",
    "X_train, y_train = train['text'], train['label']\n",
    "X_test, y_test = test['text'], test['label']\n",
    "X_valid, y_valid = valid['text'], valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;clf&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;clf__alpha&#x27;: [1], &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;],\n",
       "                         &#x27;vect__max_df&#x27;: [0.5], &#x27;vect__max_features&#x27;: [None],\n",
       "                         &#x27;vect__ngram_range&#x27;: [(2, 2)]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;clf&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;clf__alpha&#x27;: [1], &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;],\n",
       "                         &#x27;vect__max_df&#x27;: [0.5], &#x27;vect__max_features&#x27;: [None],\n",
       "                         &#x27;vect__ngram_range&#x27;: [(2, 2)]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__alpha': [1], 'vect__analyzer': ['word'],\n",
       "                         'vect__max_df': [0.5], 'vect__max_features': [None],\n",
       "                         'vect__ngram_range': [(2, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement a binary text classifier using Multinomial Naive Bayes. You are allowed to use the classes from the scikitlearn library.\n",
    "import sklearn\n",
    "\n",
    "# create a pipeline that transforms the text into a vector representation and trains a classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                        ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# train the classifier with grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'vect__analyzer': ['word'],\n",
    "    'vect__ngram_range':[(2, 2)],\n",
    "    'vect__max_df': [0.5],\n",
    "    'vect__max_features': [None],\n",
    "    'clf__alpha': [1],\n",
    "}\n",
    "\n",
    "# best parameters: {'clf__alpha': 1, 'vect__max_df': 0.5, 'vect__max_features': None}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__alpha': 1, 'vect__analyzer': 'word', 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "0.8900750000000001\n",
      "0.8996\n",
      "[[2259  236]\n",
      " [ 266 2239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      2495\n",
      "           1       0.90      0.89      0.90      2505\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.90      0.90      0.90      5000\n",
      "weighted avg       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# best model\n",
    "text_clf = grid_search.best_estimator_\n",
    "\n",
    "# predict the sentiment of the test set\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different expressions of the Bag-of-Words (BOW). These include the discrete values of the absolute word frequencies and the TF-IDF scores of the words. Consider the complete training set training set as a corpus and the respective reviews as individual documents. as individual documents. You are allowed to use the TF-IDF Vectorizer methods to be used.\n",
    "\n",
    "# create a pipeline that transforms the text into a vector representation and trains a classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "text_clf = Pipeline([('vect', TfidfVectorizer()),\n",
    "                        ('chi2', SelectKBest(chi2)),\n",
    "                        ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# train the classifier with grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'vect__analyzer': ['word'],\n",
    "    'vect__ngram_range':[(2, 2)],\n",
    "    'vect__max_df': [0.5],\n",
    "    'vect__max_features': [None],\n",
    "    'clf__alpha': [1],\n",
    "    'chi2__k': [ 5000 ]\n",
    "}\n",
    "\n",
    "# best parameters: {'chi2__k': 5000, 'clf__alpha': 1, 'vect__analyzer': 'word', 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the best parameters\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# best model\n",
    "text_clf = grid_search.best_estimator_\n",
    "\n",
    "# predict the sentiment of the test set\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "\n",
    "# POS filter\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "X_NOUN = []\n",
    "X_ADJ = []\n",
    "X_ADV = []\n",
    "for text in X_train:\n",
    "    doc = nlp(text)\n",
    "    X_NOUN.append(' '.join([token.text for token in doc if token.pos_ in ['NOUN']]))\n",
    "    X_ADJ.append(' '.join([token.text for token in doc if token.pos_ in ['ADJ']]))\n",
    "    X_ADV.append(' '.join([token.text for token in doc if token.pos_ in ['ADV']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thunderbirds mates school thunderbirds school lunch school scott one art form children movie glimpse child point theme tune score thunderbirds mornings television channel reruns series wife jonatha frakes directors chair version waste film remake marionettes homo subsp error judgment']\n",
      "['virgil disappointing only high snappy original early hopeless utter acceptable sapiens huge']\n",
      "['bitterly thankfully still completely']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./Data/X_NOUN.pkl', 'wb') as f:\n",
    "    pickle.dump(X_NOUN, f)\n",
    "\n",
    "with open('./Data/X_ADJ.pkl', 'wb') as f:\n",
    "    pickle.dump(X_ADJ, f)\n",
    "\n",
    "with open('./Data/X_ADV.pkl', 'wb') as f:\n",
    "    pickle.dump(X_ADV, f)\n",
    "\n",
    "# load the data\n",
    "# with open('X_NOUN.pkl', 'rb') as f:\n",
    "#     X_NOUN = pickle.load(f)\n",
    "\n",
    "# with open('X_ADJ.pkl', 'rb') as f:\n",
    "#     X_ADJ = pickle.load(f)\n",
    "\n",
    "# with open('X_ADV.pkl', 'rb') as f:\n",
    "#     X_ADV = pickle.load(f)\n",
    "\n",
    "\n",
    "print(X_NOUN[:1], X_ADJ[:1], X_ADV[:1], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "45 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\pipeline.py\", line 402, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\pipeline.py\", line 360, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\pipeline.py\", line 894, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\base.py\", line 851, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\", line 471, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\", line 672, in _check_params\n",
      "    raise ValueError(\n",
      "ValueError: k should be <= n_features = 5000; got 7500. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.66095  0.6753   0.66095  0.6753   0.66095  0.6753   0.661825 0.675725\n",
      " 0.661825 0.675725 0.661825 0.675725 0.66205  0.6768   0.66205  0.6768\n",
      " 0.66205  0.6768   0.691275 0.690775 0.691275 0.690775 0.691275 0.690775\n",
      " 0.6949   0.691    0.6949   0.691    0.6949   0.691    0.69425  0.69105\n",
      " 0.69425  0.69105  0.69425  0.69105  0.69995       nan 0.69995       nan\n",
      " 0.69995       nan 0.7053        nan 0.7053        nan 0.7053        nan\n",
      " 0.704075      nan 0.704075      nan 0.704075      nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "45 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\pipeline.py\", line 402, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\pipeline.py\", line 360, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\pipeline.py\", line 894, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\base.py\", line 851, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\", line 471, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\", line 672, in _check_params\n",
      "    raise ValueError(\n",
      "ValueError: k should be <= n_features = 5000; got 7500. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.670625 0.6854   0.670625 0.6854   0.670625 0.6854   0.670475 0.685425\n",
      " 0.670475 0.685425 0.670475 0.685425 0.669075 0.685475 0.669075 0.685475\n",
      " 0.669075 0.685475 0.70705  0.7074   0.70705  0.7074   0.70705  0.7074\n",
      " 0.707575 0.70775  0.707575 0.70775  0.707575 0.70775  0.70725  0.7077\n",
      " 0.70725  0.7077   0.70725  0.7077   0.7184        nan 0.7184        nan\n",
      " 0.7184        nan 0.719525      nan 0.719525      nan 0.719525      nan\n",
      " 0.719975      nan 0.719975      nan 0.719975      nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "45 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\pipeline.py\", line 402, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\pipeline.py\", line 360, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\pipeline.py\", line 894, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\base.py\", line 851, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\", line 471, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\", line 672, in _check_params\n",
      "    raise ValueError(\n",
      "ValueError: k should be <= n_features = 5000; got 7500. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Programme\\GitKrakenRepos\\WK_2626_Applied_Natural_Language_Processing\\venv_nlp\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.653875 0.658425 0.653875 0.658425 0.653875 0.658425 0.6561   0.659375\n",
      " 0.6561   0.659375 0.6561   0.659375 0.6569   0.6603   0.6569   0.6603\n",
      " 0.6569   0.6603   0.664125 0.66895  0.664125 0.66895  0.664125 0.66895\n",
      " 0.66795  0.668425 0.66795  0.668425 0.66795  0.668425 0.669025 0.66905\n",
      " 0.669025 0.66905  0.669025 0.66905  0.665975      nan 0.665975      nan\n",
      " 0.665975      nan 0.67195       nan 0.67195       nan 0.67195       nan\n",
      " 0.673325      nan 0.673325      nan 0.673325      nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Check if using a POS tag filter gives better results (e.g. only nouns, adjectives and adverbs). results (e.g. only nouns, adjectives and adverbs). The spaCy library can be used for this purpose\n",
    "\n",
    "# create a pipeline that transforms the text into a vector representation and trains a classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "\n",
    "text_clf = Pipeline([('vect', TfidfVectorizer()),\n",
    "                        ('chi2', SelectKBest(chi2)),\n",
    "                        ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# train the classifier with grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'vect__analyzer': ['word'],\n",
    "    'vect__ngram_range':[(2, 2)],\n",
    "    'vect__max_df': [0.3, 0.5, 0.7],\n",
    "    'vect__max_features': [None, 5000],\n",
    "    'clf__alpha': [0.1, 0.5, 1],\n",
    "    'chi2__k': [ 2000, 5000, 7500 ]\n",
    "}\n",
    "\n",
    "grid_search_NOUN = grid_search_ADJ = grid_search_ADV = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search_NOUN.fit(X_NOUN, y_train)\n",
    "grid_search_ADJ.fit(X_ADJ, y_train)\n",
    "grid_search_ADV.fit(X_ADV, y_train)\n",
    "\n",
    "# best model for each POS tag\n",
    "text_clf_NOUN = grid_search_NOUN.best_estimator_\n",
    "text_clf_ADJ = grid_search_ADJ.best_estimator_\n",
    "text_clf_ADV = grid_search_ADV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chi2__k': 7500, 'clf__alpha': 1, 'vect__analyzer': 'word', 'vect__max_df': 0.3, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "{'chi2__k': 7500, 'clf__alpha': 1, 'vect__analyzer': 'word', 'vect__max_df': 0.3, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "{'chi2__k': 7500, 'clf__alpha': 1, 'vect__analyzer': 'word', 'vect__max_df': 0.3, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n"
     ]
    }
   ],
   "source": [
    "# best parameters for each POS tag\n",
    "print(grid_search_NOUN.best_params_)\n",
    "print(grid_search_ADJ.best_params_)\n",
    "print(grid_search_ADV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN\n",
      "0.500475\n",
      "[[20017     2]\n",
      " [19979     2]] \n",
      "\n",
      "ADJ\n",
      "[[19376   643]\n",
      " [19139   842]]\n",
      "0.50545 \n",
      "\n",
      "ADV\n",
      "0.778075\n",
      "[[16675  3344]\n",
      " [ 5533 14448]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare the accuracy of the models\n",
    "y_pred_NOUN = text_clf_NOUN.predict(X_NOUN)\n",
    "y_pred_ADJ = text_clf_ADJ.predict(X_ADJ)\n",
    "y_pred_ADV = text_clf_ADV.predict(X_ADV)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# print the accuracy\n",
    "# print the confusion matrix\n",
    "\n",
    "print('NOUN')\n",
    "print(accuracy_score(y_train, y_pred_NOUN))\n",
    "print(confusion_matrix(y_train, y_pred_NOUN), '\\n')\n",
    "\n",
    "print('ADJ')\n",
    "print(confusion_matrix(y_train, y_pred_ADJ))\n",
    "print(accuracy_score(y_train, y_pred_ADJ), '\\n')\n",
    "\n",
    "print('ADV')\n",
    "print(accuracy_score(y_train, y_pred_ADV))\n",
    "print(confusion_matrix(y_train, y_pred_ADV), '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bfbe6ddc4272340f0f978578beb76b4382f244c22a2ece111e776d98fa2d356"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

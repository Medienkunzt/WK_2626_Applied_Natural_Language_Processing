{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\THM\\ANLP\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import spacy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  label\n0  I grew up (b. 1965) watching and loving the Th...      0\n1  When I put this movie in my DVD player, and sa...      0\n2  Why do people who do not know what a particula...      0\n3  Even though I have great interest in Biblical ...      0\n4  Im a die hard Dads Army fan and nothing will e...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I grew up (b. 1965) watching and loving the Th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When I put this movie in my DVD player, and sa...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do people who do not know what a particula...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Even though I have great interest in Biblical ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Im a die hard Dads Army fan and nothing will e...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open csv file\n",
    "train = pd.read_csv('./data/IMDBsentiment/Train.csv')\n",
    "test = pd.read_csv('./data/IMDBsentiment/Test.csv')\n",
    "valid = pd.read_csv('./data/IMDBsentiment/Valid.csv')\n",
    "\n",
    "# show first 5 rows\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all characters except a-z, A-Z, 0-9, äöüÄÖÜß, ., !, ?\n",
    "# remove double spaces\n",
    "# convert to lower case\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9äöüÄÖÜß.,!?]', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  label\n0  i grew up b. 1965 watching and loving the thun...      0\n1  when i put this movie in my dvd player, and sa...      0\n2  why do people who do not know what a particula...      0\n3  even though i have great interest in biblical ...      0\n4  im a die hard dads army fan and nothing will e...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i grew up b. 1965 watching and loving the thun...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>when i put this movie in my dvd player, and sa...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>why do people who do not know what a particula...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>even though i have great interest in biblical ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>im a die hard dads army fan and nothing will e...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = train['text'].apply(clean_text)\n",
    "test['text'] = test['text'].apply(clean_text)\n",
    "valid['text'] = valid['text'].apply(clean_text)\n",
    "\n",
    "# show first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and labels\n",
    "X_train, y_train = train['text'], train['label']\n",
    "X_test, y_test = test['text'], test['label']\n",
    "X_valid, y_valid = valid['text'], valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=Pipeline(steps=[('vect', CountVectorizer()),\n                                       ('clf', MultinomialNB())]),\n             n_jobs=-1,\n             param_grid={'clf__alpha': [1], 'vect__analyzer': ['word'],\n                         'vect__max_df': [0.5], 'vect__max_features': [None],\n                         'vect__ngram_range': [(2, 2)]},\n             verbose=1)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n                                       (&#x27;clf&#x27;, MultinomialNB())]),\n             n_jobs=-1,\n             param_grid={&#x27;clf__alpha&#x27;: [1], &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;],\n                         &#x27;vect__max_df&#x27;: [0.5], &#x27;vect__max_features&#x27;: [None],\n                         &#x27;vect__ngram_range&#x27;: [(2, 2)]},\n             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n                                       (&#x27;clf&#x27;, MultinomialNB())]),\n             n_jobs=-1,\n             param_grid={&#x27;clf__alpha&#x27;: [1], &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;],\n                         &#x27;vect__max_df&#x27;: [0.5], &#x27;vect__max_features&#x27;: [None],\n                         &#x27;vect__ngram_range&#x27;: [(2, 2)]},\n             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement a binary text classifier using Multinomial Naive Bayes. You are allowed to use the classes from the scikitlearn library.\n",
    "\n",
    "# create a pipeline that transforms the text into a vector representation and trains a classifier\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                        ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# train the classifier with grid search\n",
    "\n",
    "parameters = {\n",
    "    'vect__analyzer': ['word'],\n",
    "    'vect__ngram_range':[(2, 2)],\n",
    "    'vect__max_df': [0.5],\n",
    "    'vect__max_features': [None],\n",
    "    'clf__alpha': [1],\n",
    "}\n",
    "\n",
    "# best parameters: {'clf__alpha': 1, 'vect__max_df': 0.5, 'vect__max_features': None}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__alpha': 1, 'vect__analyzer': 'word', 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "0.8900750000000001\n",
      "0.8996\n",
      "[[2259  236]\n",
      " [ 266 2239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      2495\n",
      "           1       0.90      0.89      0.90      2505\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.90      0.90      0.90      5000\n",
      "weighted avg       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# best model\n",
    "text_clf = grid_search.best_estimator_\n",
    "\n",
    "# predict the sentiment of the test set\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n                                       ('chi2',\n                                        SelectKBest(score_func=<function chi2 at 0x00000202507BEB00>)),\n                                       ('clf', MultinomialNB())]),\n             n_jobs=-1,\n             param_grid={'chi2__k': [5000], 'clf__alpha': [1],\n                         'vect__analyzer': ['word'], 'vect__max_df': [0.5],\n                         'vect__max_features': [None],\n                         'vect__ngram_range': [(2, 2)]},\n             verbose=1)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n                                       (&#x27;chi2&#x27;,\n                                        SelectKBest(score_func=&lt;function chi2 at 0x00000202507BEB00&gt;)),\n                                       (&#x27;clf&#x27;, MultinomialNB())]),\n             n_jobs=-1,\n             param_grid={&#x27;chi2__k&#x27;: [5000], &#x27;clf__alpha&#x27;: [1],\n                         &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;], &#x27;vect__max_df&#x27;: [0.5],\n                         &#x27;vect__max_features&#x27;: [None],\n                         &#x27;vect__ngram_range&#x27;: [(2, 2)]},\n             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n                                       (&#x27;chi2&#x27;,\n                                        SelectKBest(score_func=&lt;function chi2 at 0x00000202507BEB00&gt;)),\n                                       (&#x27;clf&#x27;, MultinomialNB())]),\n             n_jobs=-1,\n             param_grid={&#x27;chi2__k&#x27;: [5000], &#x27;clf__alpha&#x27;: [1],\n                         &#x27;vect__analyzer&#x27;: [&#x27;word&#x27;], &#x27;vect__max_df&#x27;: [0.5],\n                         &#x27;vect__max_features&#x27;: [None],\n                         &#x27;vect__ngram_range&#x27;: [(2, 2)]},\n             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n                (&#x27;chi2&#x27;,\n                 SelectKBest(score_func=&lt;function chi2 at 0x00000202507BEB00&gt;)),\n                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(score_func=&lt;function chi2 at 0x00000202507BEB00&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with different expressions of the Bag-of-Words (BOW). These include the discrete values of the absolute word frequencies and the TF-IDF scores of the words. Consider the complete training set training set as a corpus and the respective reviews as individual documents. as individual documents. You are allowed to use the TF-IDF Vectorizer methods to be used.\n",
    "\n",
    "# create a pipeline that transforms the text into a vector representation and trains a classifier\n",
    "text_clf = Pipeline([('vect', TfidfVectorizer()),\n",
    "                        ('chi2', SelectKBest(chi2)),\n",
    "                        ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# train the classifier with grid search\n",
    "\n",
    "parameters = {\n",
    "    'vect__analyzer': ['word'],\n",
    "    'vect__ngram_range':[(2, 2)],\n",
    "    'vect__max_df': [0.5],\n",
    "    'vect__max_features': [None],\n",
    "    'clf__alpha': [1],\n",
    "    'chi2__k': [ 5000 ]\n",
    "}\n",
    "\n",
    "# best parameters: {'chi2__k': 5000, 'clf__alpha': 1, 'vect__analyzer': 'word', 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chi2__k': 5000, 'clf__alpha': 1, 'vect__analyzer': 'word', 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "0.88355\n",
      "0.8822\n",
      "[[2148  347]\n",
      " [ 242 2263]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88      2495\n",
      "           1       0.87      0.90      0.88      2505\n",
      "\n",
      "    accuracy                           0.88      5000\n",
      "   macro avg       0.88      0.88      0.88      5000\n",
      "weighted avg       0.88      0.88      0.88      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# best model\n",
    "text_clf = grid_search.best_estimator_\n",
    "\n",
    "# predict the sentiment of the test set\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "# print the accuracy\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [11], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m X_ADV \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m X_train:\n\u001B[1;32m----> 9\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     X_NOUN\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([token\u001B[38;5;241m.\u001B[39mtext \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m doc \u001B[38;5;28;01mif\u001B[39;00m token\u001B[38;5;241m.\u001B[39mpos_ \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNOUN\u001B[39m\u001B[38;5;124m'\u001B[39m]]))\n\u001B[0;32m     11\u001B[0m     X_ADJ\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([token\u001B[38;5;241m.\u001B[39mtext \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m doc \u001B[38;5;28;01mif\u001B[39;00m token\u001B[38;5;241m.\u001B[39mpos_ \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mADJ\u001B[39m\u001B[38;5;124m'\u001B[39m]]))\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\spacy\\language.py:1026\u001B[0m, in \u001B[0;36mLanguage.__call__\u001B[1;34m(self, text, disable, component_cfg)\u001B[0m\n\u001B[0;32m   1024\u001B[0m     error_handler \u001B[38;5;241m=\u001B[39m proc\u001B[38;5;241m.\u001B[39mget_error_handler()\n\u001B[0;32m   1025\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1026\u001B[0m     doc \u001B[38;5;241m=\u001B[39m proc(doc, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcomponent_cfg\u001B[38;5;241m.\u001B[39mget(name, {}))  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m   1027\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1028\u001B[0m     \u001B[38;5;66;03m# This typically happens if a component is not initialized\u001B[39;00m\n\u001B[0;32m   1029\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE109\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001B[0m, in \u001B[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:253\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.predict\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:274\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\model.py:315\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutT:\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001B[39;00m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001B[39;00m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 315\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\spacy\\ml\\tb_framework.py:33\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(model, X, is_train):\n\u001B[1;32m---> 33\u001B[0m     step_model \u001B[38;5;241m=\u001B[39m \u001B[43mParserStepModel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[43munseen_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munseen_classes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_upper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhas_upper\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m step_model, step_model\u001B[38;5;241m.\u001B[39mfinish_steps\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:213\u001B[0m, in \u001B[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "    \u001B[1;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001B[0m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\layers\\with_array.py:32\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, Xseq, is_train)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m     29\u001B[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001B[38;5;28mbool\u001B[39m\n\u001B[0;32m     30\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[SeqT, Callable]:\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(Xseq, Ragged):\n\u001B[1;32m---> 32\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m cast(Tuple[SeqT, Callable], \u001B[43m_ragged_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXseq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(Xseq, Padded):\n\u001B[0;32m     34\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\layers\\with_array.py:87\u001B[0m, in \u001B[0;36m_ragged_forward\u001B[1;34m(model, Xr, is_train)\u001B[0m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_ragged_forward\u001B[39m(\n\u001B[0;32m     84\u001B[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001B[38;5;28mbool\u001B[39m\n\u001B[0;32m     85\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Ragged, Callable]:\n\u001B[0;32m     86\u001B[0m     layer: Model[ArrayXd, ArrayXd] \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m---> 87\u001B[0m     Y, get_dX \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataXd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackprop\u001B[39m(dYr: Ragged) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Ragged:\n\u001B[0;32m     90\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m Ragged(get_dX(dYr\u001B[38;5;241m.\u001B[39mdataXd), dYr\u001B[38;5;241m.\u001B[39mlengths)\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(model: Model[InT, OutT], X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m---> 44\u001B[0m     Ys, callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m[layer(X, is_train\u001B[38;5;241m=\u001B[39mis_train) \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers])\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(Ys[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m     46\u001B[0m         data_l, backprop \u001B[38;5;241m=\u001B[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(model: Model[InT, OutT], X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m---> 44\u001B[0m     Ys, callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m[\u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers])\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(Ys[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m     46\u001B[0m         data_l, backprop \u001B[38;5;241m=\u001B[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\THM\\ANLP\\lib\\site-packages\\thinc\\layers\\hashembed.py:71\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, ids, is_train)\u001B[0m\n\u001B[0;32m     69\u001B[0m seed: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mattrs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     70\u001B[0m keys \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mhash(ids, seed) \u001B[38;5;241m%\u001B[39m nV\n\u001B[1;32m---> 71\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgather_add\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvectors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     72\u001B[0m drop_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_train:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "# POS filter\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "X_NOUN = []\n",
    "X_ADJ = []\n",
    "X_ADV = []\n",
    "for text in X_train:\n",
    "    doc = nlp(text)\n",
    "    X_NOUN.append(' '.join([token.text for token in doc if token.pos_ in ['NOUN']]))\n",
    "    X_ADJ.append(' '.join([token.text for token in doc if token.pos_ in ['ADJ']]))\n",
    "    X_ADV.append(' '.join([token.text for token in doc if token.pos_ in ['ADV']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/X_NOUN.pkl', 'wb') as f:\n",
    "    pickle.dump(X_NOUN, f)\n",
    "\n",
    "with open('./Data/X_ADJ.pkl', 'wb') as f:\n",
    "    pickle.dump(X_ADJ, f)\n",
    "\n",
    "with open('./Data/X_ADV.pkl', 'wb') as f:\n",
    "    pickle.dump(X_ADV, f)\n",
    "\n",
    "# load the data\n",
    "# with open('X_NOUN.pkl', 'rb') as f:\n",
    "#     X_NOUN = pickle.load(f)\n",
    "\n",
    "# with open('X_ADJ.pkl', 'rb') as f:\n",
    "#     X_ADJ = pickle.load(f)\n",
    "\n",
    "# with open('X_ADV.pkl', 'rb') as f:\n",
    "#     X_ADV = pickle.load(f)\n",
    "\n",
    "\n",
    "print(X_NOUN[:1], X_ADJ[:1], X_ADV[:1], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if using a POS tag filter gives better results (e.g. only nouns, adjectives and adverbs). results (e.g. only nouns, adjectives and adverbs). The spaCy library can be used for this purpose\n",
    "\n",
    "# create a pipeline that transforms the text into a vector representation and trains a classifier\n",
    "\n",
    "text_clf = Pipeline([('vect', TfidfVectorizer()),\n",
    "                        ('chi2', SelectKBest(chi2)),\n",
    "                        ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# train the classifier with grid search\n",
    "\n",
    "parameters = {\n",
    "    'vect__analyzer': ['word'],\n",
    "    'vect__ngram_range':[(2, 2)],\n",
    "    'vect__max_df': [0.3, 0.5, 0.7],\n",
    "    'vect__max_features': [None, 5000],\n",
    "    'clf__alpha': [0.1, 0.5, 1],\n",
    "    'chi2__k': [ 2000, 5000, 7500 ]\n",
    "}\n",
    "\n",
    "grid_search_NOUN = grid_search_ADJ = grid_search_ADV = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search_NOUN.fit(X_NOUN, y_train)\n",
    "grid_search_ADJ.fit(X_ADJ, y_train)\n",
    "grid_search_ADV.fit(X_ADV, y_train)\n",
    "\n",
    "# best model for each POS tag\n",
    "text_clf_NOUN = grid_search_NOUN.best_estimator_\n",
    "text_clf_ADJ = grid_search_ADJ.best_estimator_\n",
    "text_clf_ADV = grid_search_ADV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters for each POS tag\n",
    "print(grid_search_NOUN.best_params_)\n",
    "print(grid_search_ADJ.best_params_)\n",
    "print(grid_search_ADV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the accuracy of the models\n",
    "y_pred_NOUN = text_clf_NOUN.predict(X_NOUN)\n",
    "y_pred_ADJ = text_clf_ADJ.predict(X_ADJ)\n",
    "y_pred_ADV = text_clf_ADV.predict(X_ADV)\n",
    "\n",
    "# print the accuracy\n",
    "# print the confusion matrix\n",
    "\n",
    "print('NOUN')\n",
    "print(accuracy_score(y_train, y_pred_NOUN))\n",
    "print(confusion_matrix(y_train, y_pred_NOUN), '\\n')\n",
    "\n",
    "print('ADJ')\n",
    "print(confusion_matrix(y_train, y_pred_ADJ))\n",
    "print(accuracy_score(y_train, y_pred_ADJ), '\\n')\n",
    "\n",
    "print('ADV')\n",
    "print(accuracy_score(y_train, y_pred_ADV))\n",
    "print(confusion_matrix(y_train, y_pred_ADV), '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bfbe6ddc4272340f0f978578beb76b4382f244c22a2ece111e776d98fa2d356"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(\"./data/wikipedia300K.txt\", \"r\", encoding=\"utf-8\") as inf:\n",
    "    text = inf.read()\n",
    "sentences = text.split(\"\\n\")\n",
    "sentences_cleaned = []\n",
    "for x in sentences:\n",
    "    x = re.sub(r\"[^a-zA-Z0-9äöüÄÖÜß\\.,!\\?]\", \" \", x)\n",
    "    x = re.sub(' +', ' ', x)\n",
    "    x = x.lower()\n",
    "    sentences_cleaned.append(x)\n",
    "sentences = sentences_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "bigrams = []\n",
    "unigrams = []\n",
    "for sent in sentences: #Über alle Sätze iterieren\n",
    "    if len(sent) < 2: #Sätze die weniger als zwei Token haben werden übersprungen\n",
    "        continue\n",
    "    sent = \"<s>\" + sent\n",
    "    sent = sent + \"</s>\"\n",
    "    words = sent.split()\n",
    "    tmp_bigrams = list(ngrams(words, 2))#Bigramme bilden\n",
    "    bigrams += tmp_bigrams#Bigramme zur Liste hinzufügen\n",
    "    unigrams += words#Wörter zu der Liste aller Unigramme hinzufügen\n",
    "\n",
    "bigram_counter = Counter(bigrams)\n",
    "bigrams = dict(bigram_counter)\n",
    "unigram_counter = Counter(unigrams)\n",
    "unigrams = dict(unigram_counter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', '102') 0.34856679286100595\n",
      "('102', 'gefangene,') 0.6557377049180327\n",
      "('gefangene,', 'die') 0.8928571428571428\n",
      "('die', 'am') 0.2230343191845687\n",
      "('am', 'tor') 0.149655811490601\n",
      "('tor', 'von') 0.4403114186851211\n",
      "('von', 'isin') 0.3085801001476999\n",
      "('isin', 'gefangen') 0.8\n",
      "('gefangen', 'gesetzt') 0.1818181818181818\n",
      "('gesetzt', 'wurden,') 0.293859649122807\n"
     ]
    }
   ],
   "source": [
    "def kneser_ney_smooth(bigram_counts, unigram_counts, d=0.75):\n",
    "    N1 = defaultdict(int)\n",
    "    for w1, w2 in bigram_counts:\n",
    "        N1[w1] += 1\n",
    "    smoothed_probs = {}\n",
    "    for w1, w2 in bigram_counts:\n",
    "        c_w1_w2 = bigram_counts[(w1, w2)]\n",
    "        c_w1 = unigram_counts[w1]\n",
    "        smoothed_probs[(w1, w2)] = max(c_w1_w2 - d, 0) / c_w1 + (d * N1[w1] / c_w1)\n",
    "    return smoothed_probs\n",
    "\n",
    "smoothed_probs = kneser_ney_smooth(bigrams, unigrams)\n",
    "count = 0\n",
    "for key, value in smoothed_probs.items():\n",
    "    print(key, value)\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahrscheinlichkeit für 'Für die Reise zum Brandenburger Tor braucht man einige Stunden': 0.000140407844671374\n",
      "Wahrscheinlichkeit für 'Ich studiere Wirtschaftsinformatik an der Technischen Hoschule Mittelhessen in Friedberg': 0.0034243397997157045\n",
      "Wahrscheinlichkeit für 'Das Wetter ist heute nicht sehr schön.': 0.0001128991594542684\n",
      "Wahrscheinlichkeit für 'Ich habe vor kurzem ein interessantes Buch gelesen.': 0.0010275204049260103\n",
      "Wahrscheinlichkeit für 'Ich werde morgen früh joggen gehen.': 0.05818796525095558\n"
     ]
    }
   ],
   "source": [
    "def calc_sentence_prob(sentence, bigram_prob): #Die Wahrscheinlichkeit für den Auftritt des Satzes wird berechnet\n",
    "    sentence = re.sub(r\"[^a-zA-Z0-9öäüÖÄÜß\\?!-]\", \" \", sentence)#Satz bereinigen\n",
    "    sentence = [t.strip().lower() for t in sentence.split(\" \")]#Liste aus allen Wörtern erstellen und dabei alles in Kleinbuchstaben\n",
    "    sentence.insert(0, \"<s>\") #Am Satzanfang <s> einfügen\n",
    "    sentence.append(\"</s>\")#Am Satzende </s> einfügen\n",
    "    prob = 1#Prob mit Startwert 1\n",
    "    for i in range(len(sentence)-1): #Über die Liste der Sätze iterieren\n",
    "        bigram = (sentence[i], sentence[i+1])#Bigram bilden\n",
    "        if bigram in bigram_prob:#Wenn das Bigram in der Liste der Bigramme vorhanden ist multipliziere mit der Auftrittswahrscheinlichkeit des Bigrammes\n",
    "            prob *= bigram_prob[bigram]\n",
    "    return prob #Prob zurückgeben\n",
    "\n",
    "sentences = [\"Für die Reise zum Brandenburger Tor braucht man einige Stunden\", \"Ich studiere Wirtschaftsinformatik an der Technischen Hoschule Mittelhessen in Friedberg\", \"Das Wetter ist heute nicht sehr schön.\", \"Ich habe vor kurzem ein interessantes Buch gelesen.\", \"Ich werde morgen früh joggen gehen.\"]\n",
    "\n",
    "probs = []\n",
    "for s in sentences:\n",
    "    probs.append(calc_sentence_prob(s, smoothed_probs)) #Prob für alle Sätze mit dem vorher erstellten Kneser-Ney Bigramm Modell aufrufen\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Wahrscheinlichkeit für '{sentences[i]}': {probs[i]}\") #Ergebnisse ausgeben"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity für 'Für die Reise zum Brandenburger Tor braucht man einige Stunden': 7122.109183717691\n",
      "Perplexity für 'Ich studiere Wirtschaftsinformatik an der Technischen Hoschule Mittelhessen in Friedberg': 292.0270938307648\n",
      "Perplexity für 'Das Wetter ist heute nicht sehr schön.': 8857.461869811932\n",
      "Perplexity für 'Ich habe vor kurzem ein interessantes Buch gelesen.': 973.2166828083651\n",
      "Perplexity für 'Ich werde morgen früh joggen gehen.': 17.1856842851809\n"
     ]
    }
   ],
   "source": [
    "def calc_perplexity(prob):#Funktion zur Berechnung der Perplexity\n",
    "    if prob == 0:\n",
    "        return float('inf')\n",
    "    return 2**(-math.log2(prob))\n",
    "\n",
    "perplex = []\n",
    "for i in range(5):\n",
    "    perplex.append(calc_perplexity(probs[i])) #Über die Sätze iterieren und die Perplexity berechnen\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Perplexity für '{sentences[i]}': {perplex[i]}\") #Ergebnisse ausgeben"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

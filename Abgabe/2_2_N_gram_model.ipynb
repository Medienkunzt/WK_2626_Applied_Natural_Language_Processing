{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data and clean\n",
    "# each row is a sentence and the sentences are separated by a newline\n",
    "with open(\"./data/wikipedia300K.txt\", \"r\", encoding=\"utf-8\") as inf:\n",
    "    text = inf.read()\n",
    "sentences = text.split(\"\\n\")\n",
    "sentences_cleaned = []\n",
    "for x in sentences:\n",
    "    x = re.sub(r\"[^a-zA-Z0-9äöüÄÖÜß\\.,!\\?]\", \" \", x)\n",
    "    x = re.sub(' +', ' ', x)\n",
    "    x = x.lower()\n",
    "    sentences_cleaned.append(x)\n",
    "sentences = sentences_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create bigrams and unigrams\n",
    "# bigrams is a dictionary with the bigram as key and the count as value\n",
    "# unigrams is a dictionary with the unigram as key and the count as value\n",
    "# add <s> and </s> to each sentence\n",
    "bigrams = []\n",
    "unigrams = []\n",
    "for sent in sentences:\n",
    "    if len(sent) < 2:\n",
    "        continue\n",
    "    sent = \"<s>\" + sent\n",
    "    sent = sent + \"</s>\"\n",
    "    words = sent.split()\n",
    "    tmp_bigrams = list(ngrams(words, 2))\n",
    "    bigrams += tmp_bigrams\n",
    "    unigrams += words\n",
    "\n",
    "bigram_counter = Counter(bigrams)\n",
    "bigrams = dict(bigram_counter)\n",
    "unigram_counter = Counter(unigrams)\n",
    "unigrams = dict(unigram_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', '102') 0.34856679286100595\n",
      "('102', 'gefangene,') 0.6557377049180327\n",
      "('gefangene,', 'die') 0.8928571428571428\n",
      "('die', 'am') 0.2230343191845687\n",
      "('am', 'tor') 0.149655811490601\n",
      "('tor', 'von') 0.4403114186851211\n",
      "('von', 'isin') 0.3085801001476999\n",
      "('isin', 'gefangen') 0.8\n",
      "('gefangen', 'gesetzt') 0.1818181818181818\n",
      "('gesetzt', 'wurden,') 0.293859649122807\n"
     ]
    }
   ],
   "source": [
    "# Calculate the probability for each bigram\n",
    "def kneser_ney_smooth(bigram_counts, unigram_counts, d=0.75):\n",
    "    N1 = defaultdict(int)\n",
    "    for w1, w2 in bigram_counts:\n",
    "        N1[w1] += 1\n",
    "    smoothed_probs = {}\n",
    "    for w1, w2 in bigram_counts:\n",
    "        c_w1_w2 = bigram_counts[(w1, w2)]\n",
    "        c_w1 = unigram_counts[w1]\n",
    "        smoothed_probs[(w1, w2)] = max(c_w1_w2 - d, 0) / c_w1 + (d * N1[w1] / c_w1)\n",
    "    return smoothed_probs\n",
    "\n",
    "smoothed_probs = kneser_ney_smooth(bigrams, unigrams)\n",
    "count = 0\n",
    "for key, value in smoothed_probs.items():\n",
    "    print(key, value)\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahrscheinlichkeit für 'Für die Reise zum Brandenburger Tor braucht man einige Stunden': 0.000140407844671374\n",
      "Wahrscheinlichkeit für 'Ich studiere Wirtschaftsinformatik an der Technischen Hoschule Mittelhessen in Friedberg': 0.0034243397997157045\n",
      "Wahrscheinlichkeit für 'Das Wetter ist heute nicht sehr schön.': 0.0001128991594542684\n",
      "Wahrscheinlichkeit für 'Ich habe vor kurzem ein interessantes Buch gelesen.': 0.0010275204049260103\n",
      "Wahrscheinlichkeit für 'Ich werde morgen früh joggen gehen.': 0.05818796525095558\n"
     ]
    }
   ],
   "source": [
    "# Calculate the probability of a sentence\n",
    "def calc_sentence_prob(sentence, bigram_prob): #Die Wahrscheinlichkeit für den Auftritt des Satzes wird berechnet\n",
    "    sentence = re.sub(r\"[^a-zA-Z0-9öäüÖÄÜß\\?!-]\", \" \", sentence)#Satz bereinigen\n",
    "    sentence = [t.strip().lower() for t in sentence.split(\" \")]#Liste aus allen Wörtern erstellen und dabei alles in Kleinbuchstaben\n",
    "    sentence.insert(0, \"<s>\") #Am Satzanfang <s> einfügen\n",
    "    sentence.append(\"</s>\")#Am Satzende </s> einfügen\n",
    "    prob = 1#Prob mit Startwert 1\n",
    "    for i in range(len(sentence)-1): #Über die Liste der Sätze iterieren\n",
    "        bigram = (sentence[i], sentence[i+1])#Bigram bilden\n",
    "        if bigram in bigram_prob:#Wenn das Bigram in der Liste der Bigramme vorhanden ist multipliziere mit der Auftrittswahrscheinlichkeit des Bigrammes\n",
    "            prob *= bigram_prob[bigram]\n",
    "    return prob #Prob zurückgeben\n",
    "\n",
    "sentences = [\"Für die Reise zum Brandenburger Tor braucht man einige Stunden\", \"Ich studiere Wirtschaftsinformatik an der Technischen Hoschule Mittelhessen in Friedberg\", \"Das Wetter ist heute nicht sehr schön.\", \"Ich habe vor kurzem ein interessantes Buch gelesen.\", \"Ich werde morgen früh joggen gehen.\"]\n",
    "\n",
    "probs = []\n",
    "for s in sentences:\n",
    "    probs.append(calc_sentence_prob(s, smoothed_probs)) #Prob für alle Sätze mit dem vorher erstellten Kneser-Ney Bigramm Modell aufrufen\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Wahrscheinlichkeit für '{sentences[i]}': {probs[i]}\") #Ergebnisse ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity für 'Für die Reise zum Brandenburger Tor braucht man einige Stunden': 7122.109183717691\n",
      "Perplexity für 'Ich studiere Wirtschaftsinformatik an der Technischen Hoschule Mittelhessen in Friedberg': 292.0270938307648\n",
      "Perplexity für 'Das Wetter ist heute nicht sehr schön.': 8857.461869811932\n",
      "Perplexity für 'Ich habe vor kurzem ein interessantes Buch gelesen.': 973.2166828083651\n",
      "Perplexity für 'Ich werde morgen früh joggen gehen.': 17.1856842851809\n"
     ]
    }
   ],
   "source": [
    "def calc_perplexity(prob):#Funktion zur Berechnung der Perplexity\n",
    "    if prob == 0:\n",
    "        return float('inf')\n",
    "    return 2**(-math.log2(prob))\n",
    "\n",
    "perplex = []\n",
    "for i in range(5):\n",
    "    perplex.append(calc_perplexity(probs[i])) #Über die Sätze iterieren und die Perplexity berechnen\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Perplexity für '{sentences[i]}': {perplex[i]}\") #Ergebnisse ausgeben"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "58e9a580e33e381d18751b4bd6d357b368bf1dd5dbcb6db220004eb9fac133a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
